# Adam optimizer configuration

_target_: torch.optim.Adam
lr: 2e-5
weight_decay: 0.01
betas: [0.9, 0.999]
# eps: 1e-8
# amsgrad: false
