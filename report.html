<p>Group 7_</p>
<p>This repository contains the code and <a href="https://skaftenicki.github.io/dtu_mlops/">MLOps</a> pipeline for a sentiment analysis project. The primary focus of this project is not the model architecture itself, but the full machine learning lifecycle, including experimentation, reproducibility, deployment, and monitoring.</p>
<h2>Project Description</h2>
<h3>Overview</h3>
<p>The goal of this project is to build a <strong>reproducible, testable, and deployable MLOps pipeline</strong> for an NLP task. Specifically, we will train a model that predicts whether a Rotten Tomatoes <strong>critic review</strong> is positive or negative based solely on the review text. The focus is not achieving state-of-the-art performance, but rather building a clean, automated end-to-end workflow: data ingestion → preprocessing → training → evaluation → packaging → deployment, with strong MLOps practices around it.</p>
<h3>Data</h3>
<p>We will use the Kaggle dataset <a href="https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset">Rotten Tomatoes Movies and Critic Reviews Dataset</a>.</p>
<p>The dataset includes thousands of critic reviews covering many movies, along with metadata. From this raw data, we will construct our modeling dataset using the review text and an associated outcome field.</p>
<h3>Prediction target</h3>
<p>The primary task is to, based on the review text, predict whether the review is positive or negative. This is a binary classification task:</p>
<ul>
<li><code>0 = negative</code></li>
<li><code>1 = positive</code></li>
</ul>
<h3>Models</h3>
<p>We will do transfer learning using the <strong>DistilBERT (<code>distilbert-base-uncased</code>)</strong> model, fine-tuned using Hugging Face <code>transformers</code>.</p>
<p>DistilBERT is ~40% smaller and ~60% faster than BERT while retaining ~97% of its performance. This enables:</p>
<ul>
<li>Faster experimentation</li>
<li>Practical hyperparameter sweeps (W&amp;B)</li>
<li>CI-compatible training smoke tests</li>
</ul>
<h3>Training and Experimentation</h3>
<p>Our training pipeline will include:</p>
<ul>
<li><strong>Config-driven runs</strong> (Hydra)</li>
<li><strong>Experiment tracking via W&amp;B</strong> (metrics, artifact storage, training curves)</li>
<li>Checkpointing + reproducible seeds</li>
<li>Cloud Computing via Google Cloud Platform (GCP):<ul>
<li>Buckets for storing data and models (in combination with <code>dvc</code>)</li>
<li>Artifact Registry for storing container images</li>
<li>Vertex AI for training</li>
</ul>
</li>
</ul>
<h2>Installation</h2>
<p>TODO: uv prerequisite
TODO: devcontainer
TODO: native</p>
<h3><code>uv run</code> alias</h3>
<p>I recommend creating an alias <code>uvr</code> for <code>uv run</code> to make running scripts easier.
Add the following line to your <code>~/.bashrc</code> (or equivalent on Windows/Linux):</p>
<p><code>bash
echo "alias uvr='uv run'" &gt;&gt; ~/.bashrc
source ~/.bashrc</code></p>
<h3>Virtual environment</h3>
<p>Initialize the virtual environment and install dependencies with:</p>
<p><code>bash
uv sync</code></p>
<p>Activate the virtual environment with:</p>
<p><code>bash
source .venv/bin/activate</code></p>
<p>Install an optional dependency group with:</p>
<p><code>bash
uv sync --group &lt;group-name&gt;</code></p>
<p>Install all dependency groups with:</p>
<p><code>bash
uv sync --all-groups</code></p>
<h3>Dependency management</h3>
<p>Add a new dependency with (or add it straight to <code>pyproject.toml</code> and run <code>uv sync</code>):</p>
<p>```bash
uv add <package-name></p>
<h1>e.g. uv add numpy</h1>
<p>```</p>
<p>To add a development dependency, use:</p>
<p>```bash
uv add <package-name> --group dev</p>
<h1>e.g. uv add pytest --group dev</h1>
<p>```</p>
<h3>Enabling pre-commit</h3>
<p><code>bash
uvr pre-commit install
uvr pre-commit run --all-files</code></p>
<h3>Version control</h3>
<h4>GitHub</h4>
<p>Clone the repo:</p>
<p><code>bash
git clone git@github.com:schependom/DTU_ml-operations-project.git
cd DTU_ml-operations-project</code></p>
<h3>Weights &amp; Biases</h3>
<p>To use Weights &amp; Biases for experiment tracking, you need to set up your environment variables. Create a <code>.env</code> file in the project root with the following content:</p>
<p><code>bash
WANDB_API_KEY=your_api_key_here
WANDB_ENTITY=your_entity_name
WANDB_PROJECT=your_project_name
WANDB_ORGANIZATION=your_organization_name</code></p>
<h3>GCP</h3>
<h4>Authentication</h4>
<p>To get started with Google Cloud Platform (GCP), follow these steps.</p>
<p>Log in to your GCP account.</p>
<p><code>bash
gcloud auth login
gcloud auth application-default login</code></p>
<h4>Project setup</h4>
<p>Set the project</p>
<p><code>bash
gcloud config set project dtumlops-484016</code></p>
<h4>DVC remote</h4>
<p>I have created the following bucket:</p>
<p><code>bash
gs://ml_ops_project_g7</code></p>
<p>You can add it to your local DVC config with:</p>
<p><code>bash
dvc remote add -d gcp gs://ml_ops_project_g7</code></p>
<p>Then, follow the usage instructions below to pull the data.</p>
<h4>Hosting the API on Google cloud.</h4>
<p>The FastAPI app defining the API is in <code>src/ml_ops_project/api.py</code>. The corresponding dockerfile can be found in <code>dockerfiles/api.dockerfile</code>.</p>
<p>To host the API, you first need to push it to the artifact registry:
- open Docker Desktop
- Run the following command from the project root:
<code>docker build -f ./dockerfiles/api.dockerfile . -t api:latest</code>
- Tag the image (find project-id and repository-id by entering a repository in the artifact registry on Google Cloud)
<code>docker tag api europe-west1-docker.pkg.dev/&lt;project-id&gt;/&lt;repository-id&gt;/api:latest</code>
- Push the image:
<code>docker push europe-west1-docker.pkg.dev/&lt;project-id&gt;/&lt;repository-id&gt;/api:latest</code>
- Deploy a service on Cloud Run configured from the image or via the following command.
<code>gcloud run deploy &lt;service-name&gt; --image &lt;image-name&gt;:&lt;image-tag&gt; --platform managed --region europe-west1 --allow-unauthenticated</code></p>
<p>Finally, verify that it's up and running: <br />
<code>gcloud run services list</code>
<code>gcloud run services describe &lt;service-name&gt; --region europe-west1</code></p>
<h2>Usage</h2>
<p>You can use <code>invoke</code> to run common tasks. To list available tasks, run:</p>
<p>```bash
invoke --list</p>
<h1>Available tasks:</h1>
<h1></h1>
<h1>build-docs        Build documentation.</h1>
<h1>docker-build      Build docker images.</h1>
<h1>preprocess-data   Preprocess data.</h1>
<h1>serve-docs        Serve documentation.</h1>
<h1>test              Run tests.</h1>
<h1>train             Train model.</h1>
<p>```</p>
<p>Now, to run a task, use:</p>
<p>```bash
invoke <task-name></p>
<h1>e.g. invoke preprocess-data</h1>
<p>```</p>
<p>To train the model using the default configuration (<code>configs/config.yaml</code>), run either of the following commands:</p>
<p>```bash
uvr invoke train</p>
<h1>or</h1>
<p>uvr python src/ml_ops_project/train.py
```</p>
<p>When you run the training script:</p>
<ol>
<li><strong>Configuration</strong>: Hydra loads and composes configuration from <code>configs/</code>.</li>
<li><strong>Environment</strong>: The script loads environment variables from <code>.env</code>.</li>
<li><strong>WandB</strong>: Initializes tracking (if enabled) using credentials from <code>.env</code>.</li>
<li><strong>Data</strong>: Loads processed rotten tomatoes data.</li>
<li><strong>Execution</strong>: Runs the training loop, logging loss and accuracy.</li>
<li><strong>Artifacts</strong>: Saves the trained model to <code>models/model.pth</code> and training plots to <code>reports/figures/</code>.</li>
</ol>
<h3>Custom Hyperparameters (Hydra)</h3>
<p>You can override any configuration parameter from the command line:</p>
<p>```bash</p>
<h1>Change learning rate and batch size</h1>
<p>uvr src/ml_ops_project/train.py optimizer.lr=0.01 batch_size=64</p>
<h1>Change number of epochs</h1>
<p>uvr src/ml_ops_project/train.py epochs=20</p>
<h1>Disable WandB for a specific run</h1>
<p>uvr src/ml_ops_project/train.py wandb.enabled=false
```</p>
<p>Or simply modify the configs in <code>configs/</code> and run <code>uvr invoke train</code>.</p>
<h3>Hyperparameter Sweeps (WandB)</h3>
<ol>
<li>
<p><strong>Initialize the sweep</strong>:</p>
<p><code>bash
uv run wandb sweep configs/wandb/sweep.yaml</code></p>
<p>This prints a sweep ID (e.g., <code>entity/project/sweep_ID</code>).</p>
</li>
<li>
<p><strong>Start the agent</strong>:</p>
<p><code>bash
uv run wandb agent entity/project/sweep_ID</code></p>
<p>The agent will run multiple training jobs with arguments defined in <code>parameters</code> section of <code>configs/wandb/sweep.yaml</code>.</p>
</li>
<li>
<p><strong>Link the best model to the registry</strong>:</p>
<p>After the sweep is complete, you can link the best model to a WandB model registry using the provided script:</p>
<p><code>bash
uvr src/ml_ops_project/link_best_model.py --sweep-id entity/project/sweep_ID</code></p>
</li>
</ol>
<h3>Model Registry Management</h3>
<p>To link the best model from a specific hyperparameter sweep to the registry, run:</p>
<p><code>bash
uvr src/ml_ops/link_best_model.py --sweep-id &lt;sweep_id&gt;</code></p>
<h3>DVC</h3>
<p>Pull data from DVC remote:</p>
<p><code>bash
uv run dvc pull</code></p>
<p>For data version control:</p>
<p><code>bash
dvc add data
git add data.dvc # or `git add .`
git commit -m "Add new data"
git tag -a v2.0 -m "Version 2.0"
dvc push
git push origin main --tags</code></p>
<p>Or simply use (possible thanks to <code>tasks.py</code>):</p>
<p><code>bash
uvr invoke dvc --folder 'data' --message 'Add new data'</code></p>
<p>To go back to a specific version later, you can checkout the git tag:</p>
<p><code>bash
git switch v1.0 # or `git checkout v1.0`
dvc checkout</code></p>
<p>To go back to the latest version, use:</p>
<p><code>bash
git switch main # or `git checkout main`
dvc checkout</code></p>
<h2>Containerization</h2>
<p>Docker containers provide isolated, reproducible environments for training and evaluating models. This project includes optimized Dockerfiles for both operations.</p>
<h3>Building Docker Images</h3>
<p>Build the training image:</p>
<p><code>bash
docker build -f dockerfiles/train.dockerfile . -t train:latest</code></p>
<p>Build the evaluation image:</p>
<p><code>bash
docker build -f dockerfiles/evaluate.dockerfile . -t evaluate:latest</code></p>
<details>
<summary>Cross-platform builds (e.g., building for AMD64 on ARM Mac)</summary>

Some systems (like Apple M1/M2 Macs) use ARM architecture, which can lead to compatibility issues when sharing Docker images with others using AMD64 architecture (common in cloud and many desktops). To ensure compatibility, you can build images for a specific platform using the `--platform` flag.

```bash
# ARM Mac (Apple Silicon) -> AMD64
docker build --platform linux/amd64 -f dockerfiles/train.dockerfile . -t train:latest

# Windows on AMD64 -> ARM64 (e.g. Apple Silicon)
docker build --platform linux/arm64 -f dockerfiles/train.dockerfile . -t train:latest
```

</details>

<h3>Running Docker Containers</h3>
<p>Run training (using configurations in <code>configs/</code>):</p>
<p><code>bash
docker run --rm --name train train:latest</code></p>
<p>Run training with <strong>custom</strong> parameters:</p>
<p><code>bash
docker run --rm --name train train:latest &lt;parameters&gt;</code></p>
<p>Run training with a custom config file (must be included in the image or mounted as a volume):</p>
<p>```bash</p>
<h1>assumes custom_config.yaml is in <code>configs/</code></h1>
<p>docker run --rm --name train train:latest --config-name custom_config</p>
<h1>mounts custom_config.yaml from host</h1>
<p>docker run --rm --name train -v $(pwd)/configs/custom_config.yaml:/configs/custom_config.yaml train:latest --config-name custom_config
```</p>
<p>Run evaluation (requires model file in image or mounted as volume):</p>
<p>```bash
docker run --rm --name eval evaluate:latest model_checkpoint=models/model.pth</p>
<h1>Mounted</h1>
<p>docker run --rm --name eval -v $(pwd)/models/model.pth:/models/model.pth evaluate:latest model_checkpoint=/models/model.pth
```</p>
<h3>Mounting volumes</h3>
<p>Use volumes to share data between host and container.</p>
<h4>When to mount volumes?</h4>
<p>If data changes frequently, or if you want to automatically sync outputs (models, reports) to your host machine, use mounted volumes:</p>
<ul>
<li>Models (<code>models/</code>)</li>
<li>Configs (<code>configs/</code>)</li>
</ul>
<h4>When not to mount volumes?</h4>
<p>If data is static and large, or if you want a fully self-contained container, <strong>copy</strong> data into the image during build, don't mount volumes:</p>
<ul>
<li>Data (<code>data/</code>)</li>
</ul>
<h4>Examples</h4>
<p>Run evaluation with mounted volumes (keeps models and configs on host):</p>
<p>```bash</p>
<h1>Mount model and data directories</h1>
<p>docker run --rm --name eval \
  -v $(pwd)/models:/models \
  -v $(pwd)/configs:/configs \
  evaluate:latest \
  model_checkpoint=/models/model.pth</p>
<h1>Or mount specific files</h1>
<p>docker run --rm --name eval \
  -v $(pwd)/models/model.pth:/models/model.pth \
  -v $(pwd)/configs/config.yaml:/configs/config.yaml \
  evaluate:latest \
  model_checkpoint=/models/model.pth
```</p>
<h3>Interactive Mode</h3>
<p>Debug or explore the container interactively:</p>
<p><code>bash
docker run --rm -it --entrypoint sh train:latest</code></p>
<p>Exit the container with the <code>exit</code> command.</p>
<h3>Copying Files from Container</h3>
<p>After training, copy outputs from container to host:</p>
<p>```bash</p>
<h1>Trained model</h1>
<p>docker cp experiment1:/models/model.pth models/model.pth</p>
<h1>Training statistics figure</h1>
<p>docker cp experiment1:/reports/figures/training_statistics.png reports/figures/training_statistics.png
```</p>
<p>If you mounted <code>models/</code> and <code>reports/</code> as volumes using respectively <code>-v $(pwd)/models:/models</code> and <code>-v $(pwd)/reports:/reports</code>, the files will already be on your own machine after training.</p>
<h3>Container and Image Management</h3>
<h4>Containers</h4>
<p>List all <strong>containers</strong> (running and stopped):</p>
<p>```bash
docker ps -a</p>
<h1>or <code>docker container ls -a</code></h1>
<p>```</p>
<p>Remove a specific container:</p>
<p><code>bash
docker rm train</code></p>
<p>Clean up stopped containers:</p>
<p><code>bash
docker container prune</code></p>
<h4>Images</h4>
<p>List all <strong>images</strong>:</p>
<p><code>bash
docker images</code></p>
<p>Remove a specific image (only if you want to rebuild or no longer need it):</p>
<p><code>bash
docker rmi train:latest</code></p>
<p>Clean up dangling images (unnamed <code>&lt;none&gt;</code> images from rebuilds):</p>
<p><code>bash
docker image prune</code></p>
<h4>System-wide Cleanup</h4>
<p>Clean up everything (stopped containers, dangling images, unused networks):</p>
<p><code>bash
docker system prune</code></p>
<h3>Api container</h3>
<p>Build the api image:</p>
<p><code>bash
docker build -f dockerfiles/api.dockerfile -t sentiment_api:latest .</code></p>
<p>Run the api container:</p>
<p><code>bash
docker run --env-file .env -p 8080:8080 --rm \
  -v &lt;path-to-credentials&gt;/dtumlops-cred.json:/gcp/creds.json:ro \
  -e GOOGLE_APPLICATION_CREDENTIALS=/gcp/creds.json \
  sentiment_api:latest</code></p>
<p>Note that <code>.env</code> should look something like this:</p>
<p><code>WANDB_API_KEY=...
WANDB_PROJECT=MLOps-Project
WANDB_ENTITY=MLOpsss
WANDB_ORGANIZATION=turtle_team-org</code></p>
<h3>Monitoring container</h3>
<p>Build the monitoring image:</p>
<p><code>bash
docker build -f dockerfiles/monitoring.dockerfile -t sentiment_monitoring:latest .</code></p>
<p>Run the monitoring container:</p>
<p><code>bash
docker run --env-file .env -p 8080:8080 --rm \
  -v &lt;path-to-credentials&gt;/dtumlops-cred.json:/gcp/creds.json:ro \
  -e GOOGLE_APPLICATION_CREDENTIALS=/gcp/creds.json \
  sentiment_monitoring:latest</code></p>
<p>The <code>init</code> flag is important to handle signal forwarding (e.g. <code>CTRL+C</code>) correctly.</p>